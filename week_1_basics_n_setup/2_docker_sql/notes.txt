Set up data pipeline in docker container 

1. Set up docker 
    1.1 Create the Docker file 
2. Set up Postgres SQL using docker 
    2.1 Pull the postgres image from docker 
    2.2 Build a container for postgres 
        docker run -it \
            -e POSTGRES_USER="root" \
            -e POSTGRES_PASSWORD="root" \
            -e POSTGRES_DB="ny_test" \
            -v $(pwd)/ny_taxi_postgres_data:/var/lib/postgresql/data \
            -p 5005:5432 \ 
            --network pg-network \
            --name pg-dabase \ 
            postgres:13
    2.3 Set up pgadmin container (frontend, image available in docker) to view the backend postgres database 
        docker run -it \
            -e PGADMIN_DEFAULT_EMAIL="admin@admin.com" \
            -e PGADMIN_DEFAULT_PASSWORD="root" \
            -p 8080:80 \
            dpage/pgadmin4
        2.3.1 Set up the server in pgadmin 
            host.docker.internal as the host, for some reason 
3. Data ingestion script 
    3.1 Use jupyter notebook to download, set up engine, process and load data into the set up postgres database 
    3.2 Convert the notebook into a python data ingestion script script 
        python ingest_data.py \
            --user "root" \
            --pwd "root" \
            --host "localhost" \
            --port "5005" \
            --db "ny_test" \
            --table-name "yellow_taxi_trips" \
            --url "https://github.com/DataTalksClub/nyc-tlc-data/releases/tag/yellow/yellow_tripdata_2021-01.csv.gz"
        To test the script is running 
    3.3 Update Dockerfile for package downloading and script ingestion 
        3.3.1 To build the docker container 
            docker build -t taxi_ingest:v001 .
        3.3.2 To test the container
            docker run -it --network pg-network taxi_ingest:v001 \
                --user "root" \
                --pwd "root" \
                --host "pg-database" \
                --port "5005" \
                --db "ny_test" \
                --table-name "yellow_taxi_trips" \
                --url "https://github.com/DataTalksClub/nyc-tlc-data/releases/tag/yellow/yellow_tripdata_2021-01.csv.gz"
4. Dockerise the database and the frontend interface using docker compose 
    so that the command on top are no longer needed 
    4.1 Create docker-compose.yaml to set up the services, and run docker-compose up -d (-d so you still have control for the terminal)

Side notes: 
1. set up network for connection, not needed if you have started to use docker compose 
2. docker run --it to make it interactive (e.g. so you can kill the task in terminal)







